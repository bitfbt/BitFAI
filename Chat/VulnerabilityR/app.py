import streamlit_pills as st_pills
import streamlit as st
import pandas as pd
from pandasai import SmartDataframe
from langchain_groq.chat_models import ChatGroq
from pandasai.llm.openai import OpenAI


def main():
    st.set_page_config(layout='wide')
    st.title('Conversations with your vulnerability scans')
    st.sidebar.image("images/insight.jpg", use_column_width=True)
    print("===> ",st.chat_input)
    model = st.sidebar.selectbox(
        'Step1: Choose a model',
        ['None', 'gpt','llama3-8b-8192', 'mixtral-8x7b-32768', 'gemma-7b-it'],
    )
    api_key = st.sidebar.text_input("Step2: Input your API-KEY", value="", type="password")
    uploaded_file = st.sidebar.file_uploader("Step3: Upload csv file", type={"csv"})
    csvFileObj = open("sample/sample.csv", "r")
    st.download_button("Download a Sample CSV", csvFileObj, "sample.csv", "text/csv", key='download-csv')
    
    col1, col2 = st.columns(2)
    # LLM object
    llm = None
    message = None
    question_selected = None
    query_text = None    

    with col1:
        st.markdown('Chat with the reports (CSV or Excel) and get Insights')
        chat = ""
        # Input widgets
        df_options = ["How many rows are there?", "Display the records related to XSS?", "Display the first 3 record", "Show Pie chart by all severity"]
        icons = ["","","",""]
        print("==> ",model,uploaded_file)
        if uploaded_file and api_key and model is not "None":
            # initialize the model obj
            if model == 'gpt' and api_key:
                llm = OpenAI(api_token=api_key)
            elif model == 'llama3-8b-8192' and api_key:
                llm = ChatGroq(model="llama3-8b-8192", api_key=api_key)
            elif model == 'mixtral-8x7b-32768' and api_key:
                llm = ChatGroq(model="llama3-8b-8192", api_key=api_key)
            elif model == 'gemma-7b-it' and api_key:
                llm = ChatGroq(model="llama3-8b-8192", api_key=api_key)                 
            else:
                llm = ChatGroq(model="llama3-8b-8192", api_key=api_key)
            # input
            question_selected = st_pills.pills("Quick options to try..", df_options, icons) 
            query_text = st.text_input(placeholder = "Query to the File for continue ...",value=question_selected, label="Place Your Queries")
            
            # App logic to read the uploaded file
            df = pd.read_csv(uploaded_file)
            print("LLM object ==> ",llm)
            dfai = SmartDataframe(df, config={"llm": llm})           
        else:
            st.warning("Please Upload CSV File to continue ...")

    with col2:
        pass

    #message.write(response)
    if query_text:
        print("QUERY ==> ",query_text)
        response = dfai.chat(query_text)
        print("RESPONSE TYPE ==> ",type(response))
        message = st.chat_message("assistant")
        message.write(response) 
        if type(response) is str:
            if ".png" in response:
                print("You can draw")
                st.image(response)



if __name__ == "__main__":
    main()
